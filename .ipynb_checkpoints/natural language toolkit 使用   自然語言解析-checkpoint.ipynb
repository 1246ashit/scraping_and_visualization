{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39402711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "#安裝\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a230af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet\n",
      "0                       This is introduction for NLP\n",
      "1              It is likely to be useful , to people\n",
      "2             Machine learning is the new electrcity\n",
      "3  There would be less hype around AI and more ac...\n",
      "4                                   I like this book\n",
      "5                              I want book like this\n"
     ]
    }
   ],
   "source": [
    "text=[\"This is introduction for NLP\",\n",
    "      \"It is likely to be useful , to people\",\n",
    "     \"Machine learning is the new electrcity\",\n",
    "      \"There would be less hype around AI and more action going forward\"\n",
    "      \"Python is the best tool\",\n",
    "      \"I like this book\",\n",
    "      \"I want book like this\"]\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"tweet\":text})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a216c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this book \n"
     ]
    }
   ],
   "source": [
    "#挑掉 標點符號\n",
    "import re\n",
    "s=\"I.like.this.book.\"\n",
    "s1=re.sub(r\"[^\\w\\s]\",\" \",s)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f946b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this book \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "s=\"I.like.this.book.\"\n",
    "#把標點符號掃一次\n",
    "for c in string.punctuation:\n",
    "    s=s.replace(c,\" \")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef65cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-804493a787b4>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"tweet\"]=df[\"tweet\"].str.replace(\"[^\\w\\s]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                         This is introduction for NLP\n",
       "1                 It is likely to be useful  to people\n",
       "2               Machine learning is the new electrcity\n",
       "3    There would be less hype around AI and more ac...\n",
       "4                                     I like this book\n",
       "5                                I want book like this\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].str.replace(\"[^\\w\\s]\",\"\")\n",
    "df[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315aa9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet\n",
      "0                       This is introduction for NLP\n",
      "1              It is likely to be useful , to people\n",
      "2             Machine learning is the new electrcity\n",
      "3  There would be less hype around AI and more ac...\n",
      "4                                   I like this book\n",
      "5                              I want book like this\n"
     ]
    }
   ],
   "source": [
    "#去掉停用詞\n",
    "#Stop Words\n",
    "#EX: is, the, which, on, ...\n",
    "text=[\"This is introduction for NLP\",\n",
    "      \"It is likely to be useful , to people\",\n",
    "     \"Machine learning is the new electrcity\",\n",
    "      \"There would be less hype around AI and more action going forward\"\n",
    "      \"Python is the best tool\",\n",
    "      \"I like this book\",\n",
    "      \"I want book like this\"]\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"tweet\":text})\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daecc59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what the fuck  are you kidding me '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#文字標準化\n",
    "#standardizing Text\n",
    "\n",
    "lookup_dict={\"nlp\":\"natural language processing\",\n",
    "             \"ur\":\"your\",\n",
    "             \"wbu\":\"what about you\",\n",
    "             \"wtf\":\"what the fuck\",\n",
    "            \"r\":\"are\",\n",
    "            \"ya\":\"you\"}\n",
    "\n",
    "import re\n",
    "def text_std(input_text):\n",
    "    words=input_text.split()\n",
    "    new_Words=[]\n",
    "    for word in words:\n",
    "        word=re.sub(r\"[^\\w\\s]\",\"\",word)\n",
    "        if word.lower() in lookup_dict:\n",
    "            word= lookup_dict[word.lower()]\n",
    "            new_Words.append(word)\n",
    "        else:\n",
    "            new_Words.append(word)\n",
    "    return \" \".join(new_Words)\n",
    "\n",
    "text_std(\"Wtf ? r ya kidding me ?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fcaca",
   "metadata": {},
   "source": [
    "# tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c33be",
   "metadata": {},
   "source": [
    "#把一段文章分成一句一句話，再用這些話來分析文章:  sentence tokenization\n",
    "    \n",
    "#把一句話分成一個個字 再用這些字來分析整句話 : word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d462e140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet\n",
      "0                       This is introduction for NLP\n",
      "1              It is likely to be useful , to people\n",
      "2             Machine learning is the new electrcity\n",
      "3  There would be less hype around AI and more ac...\n",
      "4                                   I like this book\n",
      "5                              I want book like this\n"
     ]
    }
   ],
   "source": [
    "#word tokenization\n",
    "\n",
    "#先創文字資料\n",
    "text=[\"This is introduction for NLP\",\n",
    "      \"It is likely to be useful , to people\",\n",
    "     \"Machine learning is the new electrcity\",\n",
    "      \"There would be less hype around AI and more action going forward\"\n",
    "      \"Python is the best tool\",\n",
    "      \"I like this book\",\n",
    "      \"I want book like this\"]\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"tweet\":text})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01d9134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'favorite', 'animal', 'is', 'cat.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先斷字\n",
    "#第一種方法\n",
    "#使用split()\n",
    "\n",
    "mystring=\"My favorite animal is cat.\"\n",
    "\n",
    "mystring.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da659d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第二種方法\n",
    "#使用nltk\n",
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955c0af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'favorite', 'animal', 'is', 'cat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "mystring=\"My favorite animal is cat\"\n",
    "nltk.word_tokenize(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103f2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#兩者有差別\n",
    "mystring=\"\"\"At eight o'clock on Thursday morning...\n",
    "Arther didn't feel very good.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568d1be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning...',\n",
       " 'Arther',\n",
       " \"didn't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aab5e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " '...',\n",
       " 'Arther',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(mystring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575666bd",
   "metadata": {},
   "source": [
    "# 分詞器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9937bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "sentence='''Sunil tweeted,\"Witness 70th Republic Day of India from Rajpath,\\\n",
    "            New Delhi. Mesmerizing performance by India Army! Awesome airshow! @india_official \\\n",
    "            @india_army #India #70thRepublic_day. For more photos ping me sunil@photo.com:)\"\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34eaf35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " '\"',\n",
       " 'Witness',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'India',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@india_official',\n",
       " '@india_army',\n",
       " '#India',\n",
       " '#70thRepublic_day',\n",
       " '.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photo.com',\n",
       " ':)',\n",
       " '\"']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_with_tweet_tokenizetion(text):\n",
    "    #架機器人\n",
    "    tweet_tokenizer=TweetTokenizer()\n",
    "    #作業\n",
    "    return tweet_tokenizer.tokenize(text)\n",
    "\n",
    "tokenize_with_tweet_tokenizetion(sentence)\n",
    "\n",
    "#不會省略表情符號\n",
    "#因為那是判斷文章的一個要素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed39ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,\"Witness',\n",
       " '70th',\n",
       " 'Republic_Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'India',\n",
       " 'Army!',\n",
       " 'Awesome',\n",
       " 'airshow!',\n",
       " '@india_official',\n",
       " '@india_army',\n",
       " '#India',\n",
       " '#70thRepublic_day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photo.com:)\"']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_with_mwe(text):\n",
    "    mwe_tokenzer=MWETokenizer()\n",
    "    mwe_tokenzer.add_mwe((\"Republic\",\"Day\"))\n",
    "    mwe_tokenzer.add_mwe((\"India\",\"Army\"))\n",
    "    return mwe_tokenzer.tokenize(text.split())\n",
    "\n",
    "\n",
    "tokenize_with_mwe(sentence)\n",
    "#這方法沒能抓到India Army因為後面加了驚嘆號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e31025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,\"Witness',\n",
       " '70th',\n",
       " 'Republic_Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Delhi.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'India_Army',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '@india_official',\n",
       " '@india_army',\n",
       " '#India',\n",
       " '#70thRepublic_day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photo.com:)\"']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#解決方法\n",
    "tokenize_with_mwe(sentence.replace(\"!\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270488e8",
   "metadata": {},
   "source": [
    "# sent_tokenize\n",
    "會自動識別大寫，不同類型的標點符號，\n",
    "利用這些資訊來分段成句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688e80ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The concerns of most 14-year-old's typically stretch from school to social encounters.\",\n",
       " 'Not for Quan Hongchan though.',\n",
       " \"The 14-year-old diving sensation -- China's youngest athlete at the Tokyo 2020 Olympics -- won a stunning gold medal in the women’s 10 meter platform diving on Thursday.\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "target=\"The concerns of most 14-year-old's typically stretch from school to social encounters.\\\n",
    "        Not for Quan Hongchan though.\\\n",
    "        The 14-year-old diving sensation -- China's youngest athlete at the Tokyo 2020 Olympics -- won a stunning gold medal in the women’s 10 meter platform diving on Thursday.\"\n",
    "\n",
    "nltk.sent_tokenize(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec6c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
